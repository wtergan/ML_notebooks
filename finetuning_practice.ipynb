{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQQN/x5Rhi49McqntFixI9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac7e0cec27bd45ef81b95db2dd1814d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db06477bc85649cead43e3e6849a7399",
              "IPY_MODEL_9b58f45c828b45b6b56040913bba8b60",
              "IPY_MODEL_057b1154b9aa4ced8c7a823e4045964a"
            ],
            "layout": "IPY_MODEL_a5daefe0486443a49876665e8cf81320"
          }
        },
        "db06477bc85649cead43e3e6849a7399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edd88f0efcda4ca194512d98767eb15e",
            "placeholder": "​",
            "style": "IPY_MODEL_c828e90b4736487b8417eb1179862112",
            "value": "100%"
          }
        },
        "9b58f45c828b45b6b56040913bba8b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c7f8dd2f12c43cc8e13a7add3f349a6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ab9e3e0b2f642d5ba8158f76c6239a0",
            "value": 1
          }
        },
        "057b1154b9aa4ced8c7a823e4045964a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1dc1e64e004a2eae70c79c3dd93dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_9ef320aabac6437bb257910ee742a27d",
            "value": " 1/1 [00:00&lt;00:00, 38.32it/s]"
          }
        },
        "a5daefe0486443a49876665e8cf81320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd88f0efcda4ca194512d98767eb15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c828e90b4736487b8417eb1179862112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c7f8dd2f12c43cc8e13a7add3f349a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab9e3e0b2f642d5ba8158f76c6239a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1dc1e64e004a2eae70c79c3dd93dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef320aabac6437bb257910ee742a27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "939b7f26b871413fb55dace046e8be4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e223f25bdc8b495588792c18db0a426a",
              "IPY_MODEL_6d7845b417944d7bb06173fa04924a80",
              "IPY_MODEL_fb41475e14864237b7517446afbf527a"
            ],
            "layout": "IPY_MODEL_37a83cab08944c1486438eeea7b4cd04"
          }
        },
        "e223f25bdc8b495588792c18db0a426a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e979d870bc2e40a7bedeeabe8cdbf2ec",
            "placeholder": "​",
            "style": "IPY_MODEL_a34357fb25844dedbed14505d038e9d9",
            "value": "Map: 100%"
          }
        },
        "6d7845b417944d7bb06173fa04924a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5e61cc1522477081cba73b8ffebb83",
            "max": 2508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_719387c42bf04442a85b5daac1fbe8ce",
            "value": 2508
          }
        },
        "fb41475e14864237b7517446afbf527a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979386cda40f46f6bc2d2d3c594240d2",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd51b56bcf746f3b60d69f8626b91a0",
            "value": " 2508/2508 [00:00&lt;00:00, 2738.56 examples/s]"
          }
        },
        "37a83cab08944c1486438eeea7b4cd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e979d870bc2e40a7bedeeabe8cdbf2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34357fb25844dedbed14505d038e9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d5e61cc1522477081cba73b8ffebb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719387c42bf04442a85b5daac1fbe8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "979386cda40f46f6bc2d2d3c594240d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd51b56bcf746f3b60d69f8626b91a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtergan/ML_notebooks/blob/main/finetuning_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bprgSS6ldg15",
        "outputId": "8a1288f6-f27f-4470-829d-b0c5059b8622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.40.2)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Basic installations:\n",
        "!pip install -q datasets accelerate loralib sentencepiece\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n",
        "\n",
        "#bitsandbytes is a package for 8-bit (and 4-bit) CUDA functions for PyTorch.\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "import sentencepiece as spm\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, LlamaTokenizer, LlamaForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just checking if the GPU is available.\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7pBSVKLdqLd",
        "outputId": "81e8f736-ae76-4c51-bf4f-79dda645c6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "OpenLLaMA: An Open Reproduction of LLaMA (version 1).\n",
        "  - 3B, 7B variants pretrained on more than 1T tokens from the RedPajama dataset (open source).\n",
        "  - Same preprocessing steps and training hyperparameters as the original LLaMA paper.\n",
        "  - 7B variant is comparable to LLaMA in evaluation.\n",
        "\"\"\"\n",
        "# Loading of the open_llama_3b model, including its weights. Changing the precision of the weights to be 8-bit, for memory conservation.\n",
        "# Using Google Colab's T4 GPU for this process.\n",
        "\n",
        "# Specifies which GPU(s) to use if multiple are available.\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "model_path = \"openlm-research/open_llama_3b\"\n",
        "\n",
        "# Creation of the open_llama_3b model.\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Creation of tokenizer. A BPE model based on sentencepiece.\n",
        "# Lets set legacy to False, so that tokens that come after special tokens will be properly handled.\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_path, legacy=False)\n",
        "\n",
        "# Lets add an <eos> pad token to the tokenizer.\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "Sr-rc4Tbdzqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can then do some testing of model generation to see if the model was created successfully.\n",
        "prompt = \"Q: What is the currently the largest animal in the world?\\nA:\"\n",
        "input_ids = tokenizer(prompt, return_tensor=\"pt\").input_ids\n",
        "\n",
        "# For some reason, return_tensor is not working. Lets change the ids list into a tensor manually.\n",
        "# We will subsequently send the resulting tensor into\n",
        "input_tensor = torch.tensor(input_ids).unsqueeze(0)\n",
        "\n",
        "# Lets set the tensor to GPU.\n",
        "input_tensor = input_tensor.to(model.device)\n",
        "\n",
        "# Output generation.\n",
        "generation_output = model.generate(input_ids=input_tensor, max_new_tokens=32)\n",
        "print(tokenizer.decode(generation_output[0]))"
      ],
      "metadata": {
        "id": "zdy7p_Ue1v1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f02656-b284-483f-b5a6-073ccb568c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'return_tensor': 'pt'} not recognized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>Q: What is the currently the largest animal in the world?\n",
            "A: The blue whale is the largest animal in the world.\n",
            "Q: What is the largest animal in the world?\n",
            "A: The blue whale is the largest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing of the model's layers, casting of the layer norm and output of the last layer in float32 for stability.\n",
        "for param in model.parameters():\n",
        "  # This line does the freezing. We will instead train the adapters.\n",
        "  # If the param\n",
        "  param.requires_grad = False\n",
        "  if param.ndim == 1:\n",
        "    # Cast the small parameters (e.g layernorm) to fp32 for stability (some parameters go to 0 or inf if set to lower precision).\n",
        "    param.data = param.data.to(torch.float32)\n",
        "\n",
        "# This reduces the number of stored activations.\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)"
      ],
      "metadata": {
        "id": "oONSo0bvd2-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using LoRA using get_peft_model utility function from peft.\n",
        "def print_trainable_parameters(model):\n",
        "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "          trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all_params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "bbKMYo4Fd5PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to get the name of the weight parameters in the model for the LoRA process.\n",
        "parameters_base_model = model.state_dict()\n",
        "for name, param in parameters_base_model.items():\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "WNOWCGgZd91P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22416e77-b832-471b-a571-d12de8152cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.embed_tokens.weight\n",
            "model.layers.0.self_attn.q_proj.weight\n",
            "model.layers.0.self_attn.q_proj.SCB\n",
            "model.layers.0.self_attn.q_proj.weight_format\n",
            "model.layers.0.self_attn.k_proj.weight\n",
            "model.layers.0.self_attn.k_proj.SCB\n",
            "model.layers.0.self_attn.k_proj.weight_format\n",
            "model.layers.0.self_attn.v_proj.weight\n",
            "model.layers.0.self_attn.v_proj.SCB\n",
            "model.layers.0.self_attn.v_proj.weight_format\n",
            "model.layers.0.self_attn.o_proj.weight\n",
            "model.layers.0.self_attn.o_proj.SCB\n",
            "model.layers.0.self_attn.o_proj.weight_format\n",
            "model.layers.0.self_attn.rotary_emb.inv_freq\n",
            "model.layers.0.mlp.gate_proj.weight\n",
            "model.layers.0.mlp.gate_proj.SCB\n",
            "model.layers.0.mlp.gate_proj.weight_format\n",
            "model.layers.0.mlp.down_proj.weight\n",
            "model.layers.0.mlp.down_proj.SCB\n",
            "model.layers.0.mlp.down_proj.weight_format\n",
            "model.layers.0.mlp.up_proj.weight\n",
            "model.layers.0.mlp.up_proj.SCB\n",
            "model.layers.0.mlp.up_proj.weight_format\n",
            "model.layers.0.input_layernorm.weight\n",
            "model.layers.0.post_attention_layernorm.weight\n",
            "model.layers.1.self_attn.q_proj.weight\n",
            "model.layers.1.self_attn.q_proj.SCB\n",
            "model.layers.1.self_attn.q_proj.weight_format\n",
            "model.layers.1.self_attn.k_proj.weight\n",
            "model.layers.1.self_attn.k_proj.SCB\n",
            "model.layers.1.self_attn.k_proj.weight_format\n",
            "model.layers.1.self_attn.v_proj.weight\n",
            "model.layers.1.self_attn.v_proj.SCB\n",
            "model.layers.1.self_attn.v_proj.weight_format\n",
            "model.layers.1.self_attn.o_proj.weight\n",
            "model.layers.1.self_attn.o_proj.SCB\n",
            "model.layers.1.self_attn.o_proj.weight_format\n",
            "model.layers.1.self_attn.rotary_emb.inv_freq\n",
            "model.layers.1.mlp.gate_proj.weight\n",
            "model.layers.1.mlp.gate_proj.SCB\n",
            "model.layers.1.mlp.gate_proj.weight_format\n",
            "model.layers.1.mlp.down_proj.weight\n",
            "model.layers.1.mlp.down_proj.SCB\n",
            "model.layers.1.mlp.down_proj.weight_format\n",
            "model.layers.1.mlp.up_proj.weight\n",
            "model.layers.1.mlp.up_proj.SCB\n",
            "model.layers.1.mlp.up_proj.weight_format\n",
            "model.layers.1.input_layernorm.weight\n",
            "model.layers.1.post_attention_layernorm.weight\n",
            "model.layers.2.self_attn.q_proj.weight\n",
            "model.layers.2.self_attn.q_proj.SCB\n",
            "model.layers.2.self_attn.q_proj.weight_format\n",
            "model.layers.2.self_attn.k_proj.weight\n",
            "model.layers.2.self_attn.k_proj.SCB\n",
            "model.layers.2.self_attn.k_proj.weight_format\n",
            "model.layers.2.self_attn.v_proj.weight\n",
            "model.layers.2.self_attn.v_proj.SCB\n",
            "model.layers.2.self_attn.v_proj.weight_format\n",
            "model.layers.2.self_attn.o_proj.weight\n",
            "model.layers.2.self_attn.o_proj.SCB\n",
            "model.layers.2.self_attn.o_proj.weight_format\n",
            "model.layers.2.self_attn.rotary_emb.inv_freq\n",
            "model.layers.2.mlp.gate_proj.weight\n",
            "model.layers.2.mlp.gate_proj.SCB\n",
            "model.layers.2.mlp.gate_proj.weight_format\n",
            "model.layers.2.mlp.down_proj.weight\n",
            "model.layers.2.mlp.down_proj.SCB\n",
            "model.layers.2.mlp.down_proj.weight_format\n",
            "model.layers.2.mlp.up_proj.weight\n",
            "model.layers.2.mlp.up_proj.SCB\n",
            "model.layers.2.mlp.up_proj.weight_format\n",
            "model.layers.2.input_layernorm.weight\n",
            "model.layers.2.post_attention_layernorm.weight\n",
            "model.layers.3.self_attn.q_proj.weight\n",
            "model.layers.3.self_attn.q_proj.SCB\n",
            "model.layers.3.self_attn.q_proj.weight_format\n",
            "model.layers.3.self_attn.k_proj.weight\n",
            "model.layers.3.self_attn.k_proj.SCB\n",
            "model.layers.3.self_attn.k_proj.weight_format\n",
            "model.layers.3.self_attn.v_proj.weight\n",
            "model.layers.3.self_attn.v_proj.SCB\n",
            "model.layers.3.self_attn.v_proj.weight_format\n",
            "model.layers.3.self_attn.o_proj.weight\n",
            "model.layers.3.self_attn.o_proj.SCB\n",
            "model.layers.3.self_attn.o_proj.weight_format\n",
            "model.layers.3.self_attn.rotary_emb.inv_freq\n",
            "model.layers.3.mlp.gate_proj.weight\n",
            "model.layers.3.mlp.gate_proj.SCB\n",
            "model.layers.3.mlp.gate_proj.weight_format\n",
            "model.layers.3.mlp.down_proj.weight\n",
            "model.layers.3.mlp.down_proj.SCB\n",
            "model.layers.3.mlp.down_proj.weight_format\n",
            "model.layers.3.mlp.up_proj.weight\n",
            "model.layers.3.mlp.up_proj.SCB\n",
            "model.layers.3.mlp.up_proj.weight_format\n",
            "model.layers.3.input_layernorm.weight\n",
            "model.layers.3.post_attention_layernorm.weight\n",
            "model.layers.4.self_attn.q_proj.weight\n",
            "model.layers.4.self_attn.q_proj.SCB\n",
            "model.layers.4.self_attn.q_proj.weight_format\n",
            "model.layers.4.self_attn.k_proj.weight\n",
            "model.layers.4.self_attn.k_proj.SCB\n",
            "model.layers.4.self_attn.k_proj.weight_format\n",
            "model.layers.4.self_attn.v_proj.weight\n",
            "model.layers.4.self_attn.v_proj.SCB\n",
            "model.layers.4.self_attn.v_proj.weight_format\n",
            "model.layers.4.self_attn.o_proj.weight\n",
            "model.layers.4.self_attn.o_proj.SCB\n",
            "model.layers.4.self_attn.o_proj.weight_format\n",
            "model.layers.4.self_attn.rotary_emb.inv_freq\n",
            "model.layers.4.mlp.gate_proj.weight\n",
            "model.layers.4.mlp.gate_proj.SCB\n",
            "model.layers.4.mlp.gate_proj.weight_format\n",
            "model.layers.4.mlp.down_proj.weight\n",
            "model.layers.4.mlp.down_proj.SCB\n",
            "model.layers.4.mlp.down_proj.weight_format\n",
            "model.layers.4.mlp.up_proj.weight\n",
            "model.layers.4.mlp.up_proj.SCB\n",
            "model.layers.4.mlp.up_proj.weight_format\n",
            "model.layers.4.input_layernorm.weight\n",
            "model.layers.4.post_attention_layernorm.weight\n",
            "model.layers.5.self_attn.q_proj.weight\n",
            "model.layers.5.self_attn.q_proj.SCB\n",
            "model.layers.5.self_attn.q_proj.weight_format\n",
            "model.layers.5.self_attn.k_proj.weight\n",
            "model.layers.5.self_attn.k_proj.SCB\n",
            "model.layers.5.self_attn.k_proj.weight_format\n",
            "model.layers.5.self_attn.v_proj.weight\n",
            "model.layers.5.self_attn.v_proj.SCB\n",
            "model.layers.5.self_attn.v_proj.weight_format\n",
            "model.layers.5.self_attn.o_proj.weight\n",
            "model.layers.5.self_attn.o_proj.SCB\n",
            "model.layers.5.self_attn.o_proj.weight_format\n",
            "model.layers.5.self_attn.rotary_emb.inv_freq\n",
            "model.layers.5.mlp.gate_proj.weight\n",
            "model.layers.5.mlp.gate_proj.SCB\n",
            "model.layers.5.mlp.gate_proj.weight_format\n",
            "model.layers.5.mlp.down_proj.weight\n",
            "model.layers.5.mlp.down_proj.SCB\n",
            "model.layers.5.mlp.down_proj.weight_format\n",
            "model.layers.5.mlp.up_proj.weight\n",
            "model.layers.5.mlp.up_proj.SCB\n",
            "model.layers.5.mlp.up_proj.weight_format\n",
            "model.layers.5.input_layernorm.weight\n",
            "model.layers.5.post_attention_layernorm.weight\n",
            "model.layers.6.self_attn.q_proj.weight\n",
            "model.layers.6.self_attn.q_proj.SCB\n",
            "model.layers.6.self_attn.q_proj.weight_format\n",
            "model.layers.6.self_attn.k_proj.weight\n",
            "model.layers.6.self_attn.k_proj.SCB\n",
            "model.layers.6.self_attn.k_proj.weight_format\n",
            "model.layers.6.self_attn.v_proj.weight\n",
            "model.layers.6.self_attn.v_proj.SCB\n",
            "model.layers.6.self_attn.v_proj.weight_format\n",
            "model.layers.6.self_attn.o_proj.weight\n",
            "model.layers.6.self_attn.o_proj.SCB\n",
            "model.layers.6.self_attn.o_proj.weight_format\n",
            "model.layers.6.self_attn.rotary_emb.inv_freq\n",
            "model.layers.6.mlp.gate_proj.weight\n",
            "model.layers.6.mlp.gate_proj.SCB\n",
            "model.layers.6.mlp.gate_proj.weight_format\n",
            "model.layers.6.mlp.down_proj.weight\n",
            "model.layers.6.mlp.down_proj.SCB\n",
            "model.layers.6.mlp.down_proj.weight_format\n",
            "model.layers.6.mlp.up_proj.weight\n",
            "model.layers.6.mlp.up_proj.SCB\n",
            "model.layers.6.mlp.up_proj.weight_format\n",
            "model.layers.6.input_layernorm.weight\n",
            "model.layers.6.post_attention_layernorm.weight\n",
            "model.layers.7.self_attn.q_proj.weight\n",
            "model.layers.7.self_attn.q_proj.SCB\n",
            "model.layers.7.self_attn.q_proj.weight_format\n",
            "model.layers.7.self_attn.k_proj.weight\n",
            "model.layers.7.self_attn.k_proj.SCB\n",
            "model.layers.7.self_attn.k_proj.weight_format\n",
            "model.layers.7.self_attn.v_proj.weight\n",
            "model.layers.7.self_attn.v_proj.SCB\n",
            "model.layers.7.self_attn.v_proj.weight_format\n",
            "model.layers.7.self_attn.o_proj.weight\n",
            "model.layers.7.self_attn.o_proj.SCB\n",
            "model.layers.7.self_attn.o_proj.weight_format\n",
            "model.layers.7.self_attn.rotary_emb.inv_freq\n",
            "model.layers.7.mlp.gate_proj.weight\n",
            "model.layers.7.mlp.gate_proj.SCB\n",
            "model.layers.7.mlp.gate_proj.weight_format\n",
            "model.layers.7.mlp.down_proj.weight\n",
            "model.layers.7.mlp.down_proj.SCB\n",
            "model.layers.7.mlp.down_proj.weight_format\n",
            "model.layers.7.mlp.up_proj.weight\n",
            "model.layers.7.mlp.up_proj.SCB\n",
            "model.layers.7.mlp.up_proj.weight_format\n",
            "model.layers.7.input_layernorm.weight\n",
            "model.layers.7.post_attention_layernorm.weight\n",
            "model.layers.8.self_attn.q_proj.weight\n",
            "model.layers.8.self_attn.q_proj.SCB\n",
            "model.layers.8.self_attn.q_proj.weight_format\n",
            "model.layers.8.self_attn.k_proj.weight\n",
            "model.layers.8.self_attn.k_proj.SCB\n",
            "model.layers.8.self_attn.k_proj.weight_format\n",
            "model.layers.8.self_attn.v_proj.weight\n",
            "model.layers.8.self_attn.v_proj.SCB\n",
            "model.layers.8.self_attn.v_proj.weight_format\n",
            "model.layers.8.self_attn.o_proj.weight\n",
            "model.layers.8.self_attn.o_proj.SCB\n",
            "model.layers.8.self_attn.o_proj.weight_format\n",
            "model.layers.8.self_attn.rotary_emb.inv_freq\n",
            "model.layers.8.mlp.gate_proj.weight\n",
            "model.layers.8.mlp.gate_proj.SCB\n",
            "model.layers.8.mlp.gate_proj.weight_format\n",
            "model.layers.8.mlp.down_proj.weight\n",
            "model.layers.8.mlp.down_proj.SCB\n",
            "model.layers.8.mlp.down_proj.weight_format\n",
            "model.layers.8.mlp.up_proj.weight\n",
            "model.layers.8.mlp.up_proj.SCB\n",
            "model.layers.8.mlp.up_proj.weight_format\n",
            "model.layers.8.input_layernorm.weight\n",
            "model.layers.8.post_attention_layernorm.weight\n",
            "model.layers.9.self_attn.q_proj.weight\n",
            "model.layers.9.self_attn.q_proj.SCB\n",
            "model.layers.9.self_attn.q_proj.weight_format\n",
            "model.layers.9.self_attn.k_proj.weight\n",
            "model.layers.9.self_attn.k_proj.SCB\n",
            "model.layers.9.self_attn.k_proj.weight_format\n",
            "model.layers.9.self_attn.v_proj.weight\n",
            "model.layers.9.self_attn.v_proj.SCB\n",
            "model.layers.9.self_attn.v_proj.weight_format\n",
            "model.layers.9.self_attn.o_proj.weight\n",
            "model.layers.9.self_attn.o_proj.SCB\n",
            "model.layers.9.self_attn.o_proj.weight_format\n",
            "model.layers.9.self_attn.rotary_emb.inv_freq\n",
            "model.layers.9.mlp.gate_proj.weight\n",
            "model.layers.9.mlp.gate_proj.SCB\n",
            "model.layers.9.mlp.gate_proj.weight_format\n",
            "model.layers.9.mlp.down_proj.weight\n",
            "model.layers.9.mlp.down_proj.SCB\n",
            "model.layers.9.mlp.down_proj.weight_format\n",
            "model.layers.9.mlp.up_proj.weight\n",
            "model.layers.9.mlp.up_proj.SCB\n",
            "model.layers.9.mlp.up_proj.weight_format\n",
            "model.layers.9.input_layernorm.weight\n",
            "model.layers.9.post_attention_layernorm.weight\n",
            "model.layers.10.self_attn.q_proj.weight\n",
            "model.layers.10.self_attn.q_proj.SCB\n",
            "model.layers.10.self_attn.q_proj.weight_format\n",
            "model.layers.10.self_attn.k_proj.weight\n",
            "model.layers.10.self_attn.k_proj.SCB\n",
            "model.layers.10.self_attn.k_proj.weight_format\n",
            "model.layers.10.self_attn.v_proj.weight\n",
            "model.layers.10.self_attn.v_proj.SCB\n",
            "model.layers.10.self_attn.v_proj.weight_format\n",
            "model.layers.10.self_attn.o_proj.weight\n",
            "model.layers.10.self_attn.o_proj.SCB\n",
            "model.layers.10.self_attn.o_proj.weight_format\n",
            "model.layers.10.self_attn.rotary_emb.inv_freq\n",
            "model.layers.10.mlp.gate_proj.weight\n",
            "model.layers.10.mlp.gate_proj.SCB\n",
            "model.layers.10.mlp.gate_proj.weight_format\n",
            "model.layers.10.mlp.down_proj.weight\n",
            "model.layers.10.mlp.down_proj.SCB\n",
            "model.layers.10.mlp.down_proj.weight_format\n",
            "model.layers.10.mlp.up_proj.weight\n",
            "model.layers.10.mlp.up_proj.SCB\n",
            "model.layers.10.mlp.up_proj.weight_format\n",
            "model.layers.10.input_layernorm.weight\n",
            "model.layers.10.post_attention_layernorm.weight\n",
            "model.layers.11.self_attn.q_proj.weight\n",
            "model.layers.11.self_attn.q_proj.SCB\n",
            "model.layers.11.self_attn.q_proj.weight_format\n",
            "model.layers.11.self_attn.k_proj.weight\n",
            "model.layers.11.self_attn.k_proj.SCB\n",
            "model.layers.11.self_attn.k_proj.weight_format\n",
            "model.layers.11.self_attn.v_proj.weight\n",
            "model.layers.11.self_attn.v_proj.SCB\n",
            "model.layers.11.self_attn.v_proj.weight_format\n",
            "model.layers.11.self_attn.o_proj.weight\n",
            "model.layers.11.self_attn.o_proj.SCB\n",
            "model.layers.11.self_attn.o_proj.weight_format\n",
            "model.layers.11.self_attn.rotary_emb.inv_freq\n",
            "model.layers.11.mlp.gate_proj.weight\n",
            "model.layers.11.mlp.gate_proj.SCB\n",
            "model.layers.11.mlp.gate_proj.weight_format\n",
            "model.layers.11.mlp.down_proj.weight\n",
            "model.layers.11.mlp.down_proj.SCB\n",
            "model.layers.11.mlp.down_proj.weight_format\n",
            "model.layers.11.mlp.up_proj.weight\n",
            "model.layers.11.mlp.up_proj.SCB\n",
            "model.layers.11.mlp.up_proj.weight_format\n",
            "model.layers.11.input_layernorm.weight\n",
            "model.layers.11.post_attention_layernorm.weight\n",
            "model.layers.12.self_attn.q_proj.weight\n",
            "model.layers.12.self_attn.q_proj.SCB\n",
            "model.layers.12.self_attn.q_proj.weight_format\n",
            "model.layers.12.self_attn.k_proj.weight\n",
            "model.layers.12.self_attn.k_proj.SCB\n",
            "model.layers.12.self_attn.k_proj.weight_format\n",
            "model.layers.12.self_attn.v_proj.weight\n",
            "model.layers.12.self_attn.v_proj.SCB\n",
            "model.layers.12.self_attn.v_proj.weight_format\n",
            "model.layers.12.self_attn.o_proj.weight\n",
            "model.layers.12.self_attn.o_proj.SCB\n",
            "model.layers.12.self_attn.o_proj.weight_format\n",
            "model.layers.12.self_attn.rotary_emb.inv_freq\n",
            "model.layers.12.mlp.gate_proj.weight\n",
            "model.layers.12.mlp.gate_proj.SCB\n",
            "model.layers.12.mlp.gate_proj.weight_format\n",
            "model.layers.12.mlp.down_proj.weight\n",
            "model.layers.12.mlp.down_proj.SCB\n",
            "model.layers.12.mlp.down_proj.weight_format\n",
            "model.layers.12.mlp.up_proj.weight\n",
            "model.layers.12.mlp.up_proj.SCB\n",
            "model.layers.12.mlp.up_proj.weight_format\n",
            "model.layers.12.input_layernorm.weight\n",
            "model.layers.12.post_attention_layernorm.weight\n",
            "model.layers.13.self_attn.q_proj.weight\n",
            "model.layers.13.self_attn.q_proj.SCB\n",
            "model.layers.13.self_attn.q_proj.weight_format\n",
            "model.layers.13.self_attn.k_proj.weight\n",
            "model.layers.13.self_attn.k_proj.SCB\n",
            "model.layers.13.self_attn.k_proj.weight_format\n",
            "model.layers.13.self_attn.v_proj.weight\n",
            "model.layers.13.self_attn.v_proj.SCB\n",
            "model.layers.13.self_attn.v_proj.weight_format\n",
            "model.layers.13.self_attn.o_proj.weight\n",
            "model.layers.13.self_attn.o_proj.SCB\n",
            "model.layers.13.self_attn.o_proj.weight_format\n",
            "model.layers.13.self_attn.rotary_emb.inv_freq\n",
            "model.layers.13.mlp.gate_proj.weight\n",
            "model.layers.13.mlp.gate_proj.SCB\n",
            "model.layers.13.mlp.gate_proj.weight_format\n",
            "model.layers.13.mlp.down_proj.weight\n",
            "model.layers.13.mlp.down_proj.SCB\n",
            "model.layers.13.mlp.down_proj.weight_format\n",
            "model.layers.13.mlp.up_proj.weight\n",
            "model.layers.13.mlp.up_proj.SCB\n",
            "model.layers.13.mlp.up_proj.weight_format\n",
            "model.layers.13.input_layernorm.weight\n",
            "model.layers.13.post_attention_layernorm.weight\n",
            "model.layers.14.self_attn.q_proj.weight\n",
            "model.layers.14.self_attn.q_proj.SCB\n",
            "model.layers.14.self_attn.q_proj.weight_format\n",
            "model.layers.14.self_attn.k_proj.weight\n",
            "model.layers.14.self_attn.k_proj.SCB\n",
            "model.layers.14.self_attn.k_proj.weight_format\n",
            "model.layers.14.self_attn.v_proj.weight\n",
            "model.layers.14.self_attn.v_proj.SCB\n",
            "model.layers.14.self_attn.v_proj.weight_format\n",
            "model.layers.14.self_attn.o_proj.weight\n",
            "model.layers.14.self_attn.o_proj.SCB\n",
            "model.layers.14.self_attn.o_proj.weight_format\n",
            "model.layers.14.self_attn.rotary_emb.inv_freq\n",
            "model.layers.14.mlp.gate_proj.weight\n",
            "model.layers.14.mlp.gate_proj.SCB\n",
            "model.layers.14.mlp.gate_proj.weight_format\n",
            "model.layers.14.mlp.down_proj.weight\n",
            "model.layers.14.mlp.down_proj.SCB\n",
            "model.layers.14.mlp.down_proj.weight_format\n",
            "model.layers.14.mlp.up_proj.weight\n",
            "model.layers.14.mlp.up_proj.SCB\n",
            "model.layers.14.mlp.up_proj.weight_format\n",
            "model.layers.14.input_layernorm.weight\n",
            "model.layers.14.post_attention_layernorm.weight\n",
            "model.layers.15.self_attn.q_proj.weight\n",
            "model.layers.15.self_attn.q_proj.SCB\n",
            "model.layers.15.self_attn.q_proj.weight_format\n",
            "model.layers.15.self_attn.k_proj.weight\n",
            "model.layers.15.self_attn.k_proj.SCB\n",
            "model.layers.15.self_attn.k_proj.weight_format\n",
            "model.layers.15.self_attn.v_proj.weight\n",
            "model.layers.15.self_attn.v_proj.SCB\n",
            "model.layers.15.self_attn.v_proj.weight_format\n",
            "model.layers.15.self_attn.o_proj.weight\n",
            "model.layers.15.self_attn.o_proj.SCB\n",
            "model.layers.15.self_attn.o_proj.weight_format\n",
            "model.layers.15.self_attn.rotary_emb.inv_freq\n",
            "model.layers.15.mlp.gate_proj.weight\n",
            "model.layers.15.mlp.gate_proj.SCB\n",
            "model.layers.15.mlp.gate_proj.weight_format\n",
            "model.layers.15.mlp.down_proj.weight\n",
            "model.layers.15.mlp.down_proj.SCB\n",
            "model.layers.15.mlp.down_proj.weight_format\n",
            "model.layers.15.mlp.up_proj.weight\n",
            "model.layers.15.mlp.up_proj.SCB\n",
            "model.layers.15.mlp.up_proj.weight_format\n",
            "model.layers.15.input_layernorm.weight\n",
            "model.layers.15.post_attention_layernorm.weight\n",
            "model.layers.16.self_attn.q_proj.weight\n",
            "model.layers.16.self_attn.q_proj.SCB\n",
            "model.layers.16.self_attn.q_proj.weight_format\n",
            "model.layers.16.self_attn.k_proj.weight\n",
            "model.layers.16.self_attn.k_proj.SCB\n",
            "model.layers.16.self_attn.k_proj.weight_format\n",
            "model.layers.16.self_attn.v_proj.weight\n",
            "model.layers.16.self_attn.v_proj.SCB\n",
            "model.layers.16.self_attn.v_proj.weight_format\n",
            "model.layers.16.self_attn.o_proj.weight\n",
            "model.layers.16.self_attn.o_proj.SCB\n",
            "model.layers.16.self_attn.o_proj.weight_format\n",
            "model.layers.16.self_attn.rotary_emb.inv_freq\n",
            "model.layers.16.mlp.gate_proj.weight\n",
            "model.layers.16.mlp.gate_proj.SCB\n",
            "model.layers.16.mlp.gate_proj.weight_format\n",
            "model.layers.16.mlp.down_proj.weight\n",
            "model.layers.16.mlp.down_proj.SCB\n",
            "model.layers.16.mlp.down_proj.weight_format\n",
            "model.layers.16.mlp.up_proj.weight\n",
            "model.layers.16.mlp.up_proj.SCB\n",
            "model.layers.16.mlp.up_proj.weight_format\n",
            "model.layers.16.input_layernorm.weight\n",
            "model.layers.16.post_attention_layernorm.weight\n",
            "model.layers.17.self_attn.q_proj.weight\n",
            "model.layers.17.self_attn.q_proj.SCB\n",
            "model.layers.17.self_attn.q_proj.weight_format\n",
            "model.layers.17.self_attn.k_proj.weight\n",
            "model.layers.17.self_attn.k_proj.SCB\n",
            "model.layers.17.self_attn.k_proj.weight_format\n",
            "model.layers.17.self_attn.v_proj.weight\n",
            "model.layers.17.self_attn.v_proj.SCB\n",
            "model.layers.17.self_attn.v_proj.weight_format\n",
            "model.layers.17.self_attn.o_proj.weight\n",
            "model.layers.17.self_attn.o_proj.SCB\n",
            "model.layers.17.self_attn.o_proj.weight_format\n",
            "model.layers.17.self_attn.rotary_emb.inv_freq\n",
            "model.layers.17.mlp.gate_proj.weight\n",
            "model.layers.17.mlp.gate_proj.SCB\n",
            "model.layers.17.mlp.gate_proj.weight_format\n",
            "model.layers.17.mlp.down_proj.weight\n",
            "model.layers.17.mlp.down_proj.SCB\n",
            "model.layers.17.mlp.down_proj.weight_format\n",
            "model.layers.17.mlp.up_proj.weight\n",
            "model.layers.17.mlp.up_proj.SCB\n",
            "model.layers.17.mlp.up_proj.weight_format\n",
            "model.layers.17.input_layernorm.weight\n",
            "model.layers.17.post_attention_layernorm.weight\n",
            "model.layers.18.self_attn.q_proj.weight\n",
            "model.layers.18.self_attn.q_proj.SCB\n",
            "model.layers.18.self_attn.q_proj.weight_format\n",
            "model.layers.18.self_attn.k_proj.weight\n",
            "model.layers.18.self_attn.k_proj.SCB\n",
            "model.layers.18.self_attn.k_proj.weight_format\n",
            "model.layers.18.self_attn.v_proj.weight\n",
            "model.layers.18.self_attn.v_proj.SCB\n",
            "model.layers.18.self_attn.v_proj.weight_format\n",
            "model.layers.18.self_attn.o_proj.weight\n",
            "model.layers.18.self_attn.o_proj.SCB\n",
            "model.layers.18.self_attn.o_proj.weight_format\n",
            "model.layers.18.self_attn.rotary_emb.inv_freq\n",
            "model.layers.18.mlp.gate_proj.weight\n",
            "model.layers.18.mlp.gate_proj.SCB\n",
            "model.layers.18.mlp.gate_proj.weight_format\n",
            "model.layers.18.mlp.down_proj.weight\n",
            "model.layers.18.mlp.down_proj.SCB\n",
            "model.layers.18.mlp.down_proj.weight_format\n",
            "model.layers.18.mlp.up_proj.weight\n",
            "model.layers.18.mlp.up_proj.SCB\n",
            "model.layers.18.mlp.up_proj.weight_format\n",
            "model.layers.18.input_layernorm.weight\n",
            "model.layers.18.post_attention_layernorm.weight\n",
            "model.layers.19.self_attn.q_proj.weight\n",
            "model.layers.19.self_attn.q_proj.SCB\n",
            "model.layers.19.self_attn.q_proj.weight_format\n",
            "model.layers.19.self_attn.k_proj.weight\n",
            "model.layers.19.self_attn.k_proj.SCB\n",
            "model.layers.19.self_attn.k_proj.weight_format\n",
            "model.layers.19.self_attn.v_proj.weight\n",
            "model.layers.19.self_attn.v_proj.SCB\n",
            "model.layers.19.self_attn.v_proj.weight_format\n",
            "model.layers.19.self_attn.o_proj.weight\n",
            "model.layers.19.self_attn.o_proj.SCB\n",
            "model.layers.19.self_attn.o_proj.weight_format\n",
            "model.layers.19.self_attn.rotary_emb.inv_freq\n",
            "model.layers.19.mlp.gate_proj.weight\n",
            "model.layers.19.mlp.gate_proj.SCB\n",
            "model.layers.19.mlp.gate_proj.weight_format\n",
            "model.layers.19.mlp.down_proj.weight\n",
            "model.layers.19.mlp.down_proj.SCB\n",
            "model.layers.19.mlp.down_proj.weight_format\n",
            "model.layers.19.mlp.up_proj.weight\n",
            "model.layers.19.mlp.up_proj.SCB\n",
            "model.layers.19.mlp.up_proj.weight_format\n",
            "model.layers.19.input_layernorm.weight\n",
            "model.layers.19.post_attention_layernorm.weight\n",
            "model.layers.20.self_attn.q_proj.weight\n",
            "model.layers.20.self_attn.q_proj.SCB\n",
            "model.layers.20.self_attn.q_proj.weight_format\n",
            "model.layers.20.self_attn.k_proj.weight\n",
            "model.layers.20.self_attn.k_proj.SCB\n",
            "model.layers.20.self_attn.k_proj.weight_format\n",
            "model.layers.20.self_attn.v_proj.weight\n",
            "model.layers.20.self_attn.v_proj.SCB\n",
            "model.layers.20.self_attn.v_proj.weight_format\n",
            "model.layers.20.self_attn.o_proj.weight\n",
            "model.layers.20.self_attn.o_proj.SCB\n",
            "model.layers.20.self_attn.o_proj.weight_format\n",
            "model.layers.20.self_attn.rotary_emb.inv_freq\n",
            "model.layers.20.mlp.gate_proj.weight\n",
            "model.layers.20.mlp.gate_proj.SCB\n",
            "model.layers.20.mlp.gate_proj.weight_format\n",
            "model.layers.20.mlp.down_proj.weight\n",
            "model.layers.20.mlp.down_proj.SCB\n",
            "model.layers.20.mlp.down_proj.weight_format\n",
            "model.layers.20.mlp.up_proj.weight\n",
            "model.layers.20.mlp.up_proj.SCB\n",
            "model.layers.20.mlp.up_proj.weight_format\n",
            "model.layers.20.input_layernorm.weight\n",
            "model.layers.20.post_attention_layernorm.weight\n",
            "model.layers.21.self_attn.q_proj.weight\n",
            "model.layers.21.self_attn.q_proj.SCB\n",
            "model.layers.21.self_attn.q_proj.weight_format\n",
            "model.layers.21.self_attn.k_proj.weight\n",
            "model.layers.21.self_attn.k_proj.SCB\n",
            "model.layers.21.self_attn.k_proj.weight_format\n",
            "model.layers.21.self_attn.v_proj.weight\n",
            "model.layers.21.self_attn.v_proj.SCB\n",
            "model.layers.21.self_attn.v_proj.weight_format\n",
            "model.layers.21.self_attn.o_proj.weight\n",
            "model.layers.21.self_attn.o_proj.SCB\n",
            "model.layers.21.self_attn.o_proj.weight_format\n",
            "model.layers.21.self_attn.rotary_emb.inv_freq\n",
            "model.layers.21.mlp.gate_proj.weight\n",
            "model.layers.21.mlp.gate_proj.SCB\n",
            "model.layers.21.mlp.gate_proj.weight_format\n",
            "model.layers.21.mlp.down_proj.weight\n",
            "model.layers.21.mlp.down_proj.SCB\n",
            "model.layers.21.mlp.down_proj.weight_format\n",
            "model.layers.21.mlp.up_proj.weight\n",
            "model.layers.21.mlp.up_proj.SCB\n",
            "model.layers.21.mlp.up_proj.weight_format\n",
            "model.layers.21.input_layernorm.weight\n",
            "model.layers.21.post_attention_layernorm.weight\n",
            "model.layers.22.self_attn.q_proj.weight\n",
            "model.layers.22.self_attn.q_proj.SCB\n",
            "model.layers.22.self_attn.q_proj.weight_format\n",
            "model.layers.22.self_attn.k_proj.weight\n",
            "model.layers.22.self_attn.k_proj.SCB\n",
            "model.layers.22.self_attn.k_proj.weight_format\n",
            "model.layers.22.self_attn.v_proj.weight\n",
            "model.layers.22.self_attn.v_proj.SCB\n",
            "model.layers.22.self_attn.v_proj.weight_format\n",
            "model.layers.22.self_attn.o_proj.weight\n",
            "model.layers.22.self_attn.o_proj.SCB\n",
            "model.layers.22.self_attn.o_proj.weight_format\n",
            "model.layers.22.self_attn.rotary_emb.inv_freq\n",
            "model.layers.22.mlp.gate_proj.weight\n",
            "model.layers.22.mlp.gate_proj.SCB\n",
            "model.layers.22.mlp.gate_proj.weight_format\n",
            "model.layers.22.mlp.down_proj.weight\n",
            "model.layers.22.mlp.down_proj.SCB\n",
            "model.layers.22.mlp.down_proj.weight_format\n",
            "model.layers.22.mlp.up_proj.weight\n",
            "model.layers.22.mlp.up_proj.SCB\n",
            "model.layers.22.mlp.up_proj.weight_format\n",
            "model.layers.22.input_layernorm.weight\n",
            "model.layers.22.post_attention_layernorm.weight\n",
            "model.layers.23.self_attn.q_proj.weight\n",
            "model.layers.23.self_attn.q_proj.SCB\n",
            "model.layers.23.self_attn.q_proj.weight_format\n",
            "model.layers.23.self_attn.k_proj.weight\n",
            "model.layers.23.self_attn.k_proj.SCB\n",
            "model.layers.23.self_attn.k_proj.weight_format\n",
            "model.layers.23.self_attn.v_proj.weight\n",
            "model.layers.23.self_attn.v_proj.SCB\n",
            "model.layers.23.self_attn.v_proj.weight_format\n",
            "model.layers.23.self_attn.o_proj.weight\n",
            "model.layers.23.self_attn.o_proj.SCB\n",
            "model.layers.23.self_attn.o_proj.weight_format\n",
            "model.layers.23.self_attn.rotary_emb.inv_freq\n",
            "model.layers.23.mlp.gate_proj.weight\n",
            "model.layers.23.mlp.gate_proj.SCB\n",
            "model.layers.23.mlp.gate_proj.weight_format\n",
            "model.layers.23.mlp.down_proj.weight\n",
            "model.layers.23.mlp.down_proj.SCB\n",
            "model.layers.23.mlp.down_proj.weight_format\n",
            "model.layers.23.mlp.up_proj.weight\n",
            "model.layers.23.mlp.up_proj.SCB\n",
            "model.layers.23.mlp.up_proj.weight_format\n",
            "model.layers.23.input_layernorm.weight\n",
            "model.layers.23.post_attention_layernorm.weight\n",
            "model.layers.24.self_attn.q_proj.weight\n",
            "model.layers.24.self_attn.q_proj.SCB\n",
            "model.layers.24.self_attn.q_proj.weight_format\n",
            "model.layers.24.self_attn.k_proj.weight\n",
            "model.layers.24.self_attn.k_proj.SCB\n",
            "model.layers.24.self_attn.k_proj.weight_format\n",
            "model.layers.24.self_attn.v_proj.weight\n",
            "model.layers.24.self_attn.v_proj.SCB\n",
            "model.layers.24.self_attn.v_proj.weight_format\n",
            "model.layers.24.self_attn.o_proj.weight\n",
            "model.layers.24.self_attn.o_proj.SCB\n",
            "model.layers.24.self_attn.o_proj.weight_format\n",
            "model.layers.24.self_attn.rotary_emb.inv_freq\n",
            "model.layers.24.mlp.gate_proj.weight\n",
            "model.layers.24.mlp.gate_proj.SCB\n",
            "model.layers.24.mlp.gate_proj.weight_format\n",
            "model.layers.24.mlp.down_proj.weight\n",
            "model.layers.24.mlp.down_proj.SCB\n",
            "model.layers.24.mlp.down_proj.weight_format\n",
            "model.layers.24.mlp.up_proj.weight\n",
            "model.layers.24.mlp.up_proj.SCB\n",
            "model.layers.24.mlp.up_proj.weight_format\n",
            "model.layers.24.input_layernorm.weight\n",
            "model.layers.24.post_attention_layernorm.weight\n",
            "model.layers.25.self_attn.q_proj.weight\n",
            "model.layers.25.self_attn.q_proj.SCB\n",
            "model.layers.25.self_attn.q_proj.weight_format\n",
            "model.layers.25.self_attn.k_proj.weight\n",
            "model.layers.25.self_attn.k_proj.SCB\n",
            "model.layers.25.self_attn.k_proj.weight_format\n",
            "model.layers.25.self_attn.v_proj.weight\n",
            "model.layers.25.self_attn.v_proj.SCB\n",
            "model.layers.25.self_attn.v_proj.weight_format\n",
            "model.layers.25.self_attn.o_proj.weight\n",
            "model.layers.25.self_attn.o_proj.SCB\n",
            "model.layers.25.self_attn.o_proj.weight_format\n",
            "model.layers.25.self_attn.rotary_emb.inv_freq\n",
            "model.layers.25.mlp.gate_proj.weight\n",
            "model.layers.25.mlp.gate_proj.SCB\n",
            "model.layers.25.mlp.gate_proj.weight_format\n",
            "model.layers.25.mlp.down_proj.weight\n",
            "model.layers.25.mlp.down_proj.SCB\n",
            "model.layers.25.mlp.down_proj.weight_format\n",
            "model.layers.25.mlp.up_proj.weight\n",
            "model.layers.25.mlp.up_proj.SCB\n",
            "model.layers.25.mlp.up_proj.weight_format\n",
            "model.layers.25.input_layernorm.weight\n",
            "model.layers.25.post_attention_layernorm.weight\n",
            "model.norm.weight\n",
            "lm_head.0.weight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  from peft import LoraConfig, get_peft_model\n",
        "\n",
        "  # Configuration parameters for the LoRA process. r is the rank, alpha is a constant in r.\n",
        "  # We scale delta_W with alpha/r. Targeting the q, k, o, and v weights.\n",
        "  # In this specific model, the weights are in a pack.\n",
        "  config = LoraConfig(\n",
        "      r=16,\n",
        "      lora_alpha=32,\n",
        "      target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "      lora_dropout=0.05,\n",
        "      bias=\"none\",\n",
        "      task_type=\"CAUSAL_LM\"\n",
        "  )\n",
        "\n",
        "  # Creation of the new lora model based on the above configuration.\n",
        "  model = get_peft_model(model, config)\n",
        "  print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "IetfdrRGeBP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626589b3-daf4-4f98-afd8-a6bea3d7eb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 10649600 || all_params: 3437123200 || trainable%: 0.309840508481046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets now train:\n",
        "from datasets import load_dataset\n",
        "data = load_dataset(\"Abirate/english_quotes\")\n",
        "# Takes argument samples and applies the tokenizer to the \"quote\" field in each sample. Done in batches.\n",
        "data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data['train'],\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=100,\n",
        "        max_steps=200,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir='outputs'\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "# Silence the warnings. Re-Enable for inference.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# No need to cache past hidden states at each step since we are training, so set as False.\n",
        "model.config.use_cache = False\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "2f3KsFtheCIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ac7e0cec27bd45ef81b95db2dd1814d8",
            "db06477bc85649cead43e3e6849a7399",
            "9b58f45c828b45b6b56040913bba8b60",
            "057b1154b9aa4ced8c7a823e4045964a",
            "a5daefe0486443a49876665e8cf81320",
            "edd88f0efcda4ca194512d98767eb15e",
            "c828e90b4736487b8417eb1179862112",
            "9c7f8dd2f12c43cc8e13a7add3f349a6",
            "1ab9e3e0b2f642d5ba8158f76c6239a0",
            "2b1dc1e64e004a2eae70c79c3dd93dcf",
            "9ef320aabac6437bb257910ee742a27d",
            "939b7f26b871413fb55dace046e8be4d",
            "e223f25bdc8b495588792c18db0a426a",
            "6d7845b417944d7bb06173fa04924a80",
            "fb41475e14864237b7517446afbf527a",
            "37a83cab08944c1486438eeea7b4cd04",
            "e979d870bc2e40a7bedeeabe8cdbf2ec",
            "a34357fb25844dedbed14505d038e9d9",
            "5d5e61cc1522477081cba73b8ffebb83",
            "719387c42bf04442a85b5daac1fbe8ce",
            "979386cda40f46f6bc2d2d3c594240d2",
            "fbd51b56bcf746f3b60d69f8626b91a0"
          ]
        },
        "outputId": "68cb73fe-fc85-4490-c31e-fb758a6b6a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/Abirate___json/Abirate--english_quotes-6e72855d06356857/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac7e0cec27bd45ef81b95db2dd1814d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2508 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "939b7f26b871413fb55dace046e8be4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 15:33, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.077300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.192300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.568300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.270000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.139300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.472100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.463900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.691700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.203000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.431500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.810900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.435100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.879900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.845000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.342600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.615100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.729400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.878200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.735700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.750200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.603500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>2.505100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.671000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.962900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2.026100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.974100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2.473500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.870800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.601400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.656700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>2.155600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.319300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.659200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.378300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>2.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>2.429700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.392300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.667700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.242400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.735400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.993800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.909500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.408000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>2.012100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.783400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.478300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.661100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.607500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.560700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.430700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.930800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.245300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.776500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.865200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.265000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>2.233800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.255400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.248400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.611700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.483000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.528800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>2.097800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.726000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.672500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.828800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.669800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.389300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.866200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.833100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.938800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.386800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.938300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.444200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.077200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.542400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.586700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.572900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.749000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.715800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.653500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.258300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.724500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.297100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.429500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.759900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.243600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.713900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.565100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.742500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>1.907600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>1.269900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.784000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>1.854700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.939700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.905200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>1.861600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.768700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.469700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>1.255500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.707000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.550700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.321700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>1.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>2.044600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>1.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>1.292500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>1.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>1.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>1.302100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>1.449800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.650700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.516400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>1.521200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>1.731800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>1.609500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.456000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>1.798900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>1.540900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>1.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>1.711000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.923100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>1.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>1.751800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>2.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>1.549300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.952700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>2.037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>1.189200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>1.546200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>1.659500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>1.936700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>1.825400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>1.564100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>1.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>1.240800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.815900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>1.894400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>1.059800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>1.864400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>2.015500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>1.358500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>1.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>1.433600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>1.631600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>2.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.438300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>1.574400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>1.776000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>1.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>1.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>1.559800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>1.154100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>1.629300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>1.541000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>1.605500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.852000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>1.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>1.176500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>1.845900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>1.784900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.316700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>2.107400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>1.380100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>1.652300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>1.393900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.677900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>1.272500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>1.615500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>1.567300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>1.905400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>1.372000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>1.332600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>1.045700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.854600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>1.727300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.154400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>1.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.765600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>1.748700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>1.877400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>1.644300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>1.834400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.864500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.132100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>1.948100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.554700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=1.6828941681981087, metrics={'train_runtime': 937.6468, 'train_samples_per_second': 3.413, 'train_steps_per_second': 0.213, 'total_flos': 5968647650073600.0, 'train_loss': 1.6828941681981087, 'epoch': 1.28})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets now do inference on the newly trained model we just created.\n",
        "batch = tokenizer(\"I believe that everything happens: \", return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "    output_tokens = model.generate(**batch, max_new_tokens=50)\n",
        "\n",
        "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrkiYnHS_1ll",
        "outputId": "8994258f-98e3-4274-c472-e4c6072a4861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " I believe that everything happens: for good or for bad. I believe that everything happens for a reason. I believe that everything happens for a reason. I believe that everything happens for a reason. I believe that everything happens for a reason. I believe that everything happens for a reason\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "91d5OmJ19y_v"
      }
    }
  ]
}